{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15a44a6e",
   "metadata": {},
   "source": [
    "# Value-Difference Based Q-Learning\n",
    "\n",
    "Preston Whitcomb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b705a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gymnasium\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from agent import Agent\n",
    "from VDBE_agent import VDBE_agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b71bdf57",
   "metadata": {},
   "source": [
    "### Graphing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fcb608a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_q_table_magnitude(q_values : dict):\n",
    "    # calculate L1 norm of q_value matrix \n",
    "    # each key is a column, each value of the key is a row element\n",
    "    # we take the norm of all columns, \n",
    "    # then find the max for the overall matrix norm\n",
    "    norms = []\n",
    "    for key in q_values.keys():\n",
    "        n = np.linalg.norm(q_values[key])\n",
    "        norms.append(n)\n",
    "    norm_max = max(norms)\n",
    "    return norm_max\n",
    "\n",
    "def graph_x_over_time(x : list, x_label : str, y_label : str, title : str):\n",
    "    fig, axs = plt.subplots()\n",
    "    axs.plot(x)\n",
    "    axs.set_xlabel(x_label)\n",
    "    axs.set_xlabel(y_label)\n",
    "    axs.set_title(title)\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4354da4c",
   "metadata": {},
   "source": [
    "# Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc7257c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(agent : Agent, num_episodes=10_000, render=False):\n",
    "    env = gymnasium.make(\"Taxi-v3\", render_mode=\"human\" if render else None)\n",
    "\n",
    "    for _ in range(num_episodes):\n",
    "        # Reset environment to start a new episode\n",
    "        observation, info = env.reset()\n",
    "\n",
    "        episode_over = False\n",
    "        total_reward = 0\n",
    "\n",
    "        while not episode_over:\n",
    "            # Choose an action\n",
    "            action = agent.pi(observation)\n",
    "\n",
    "            # Take the action and see what happens\n",
    "            new_observation, reward, terminated, truncated, info = env.step(action)\n",
    "\n",
    "            # reward: +1 for each step the pole stays upright\n",
    "            # terminated: True if pole falls too far (agent failed)\n",
    "            # truncated: True if we hit the time limit (500 steps)\n",
    "\n",
    "            total_reward += reward\n",
    "            episode_over = terminated or truncated\n",
    "\n",
    "            agent.update_Q_learning(new_observation, action, reward, observation, episode_over)\n",
    "\n",
    "            observation = new_observation\n",
    "    env.close()\n",
    "    return agent\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "409965d4",
   "metadata": {},
   "source": [
    "# Making Agents, Env, and Training Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b80c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gymnasium.make(\"Taxi-v3\")\n",
    "\n",
    "flat_epsilon_agent = Agent([0, 1, 2, 3, 4, 5])\n",
    "epsilon_decay_agent = Agent([0, 1, 2, 3, 4, 5], epsilon=1.0, do_epsilon_decay=True)\n",
    "vdbe_agent = VDBE_agent([0, 1, 2, 3, 4, 5])\n",
    "\n",
    "num_turns_to_train = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5457d6b6",
   "metadata": {},
   "source": [
    "# Train Flat Epsilon Agent (epsilon always stays the same)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180f66f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_epsilon_agent = train(flat_epsilon_agent, num_episodes=num_turns_to_train, render=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a957a9",
   "metadata": {},
   "source": [
    "#### Visualize progress with one step: (q-update is ignored)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9141529",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train(flat_epsilon_agent, 1, render=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32eacb14",
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_epsilon_agent.Q # TODO better way to visualize convergence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86f712ed",
   "metadata": {},
   "source": [
    "# Train Epsilon Decay Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "095eab42",
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon_decay_agent = train(epsilon_decay_agent, num_episodes=num_turns_to_train, render=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275c001b",
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon_decay_agent.Q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20900daf",
   "metadata": {},
   "source": [
    "#### Visualize progress with one step: (q-update is ignored)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6b2775",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train(epsilon_decay_agent, 1, render=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b88ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon_decay_agent.Q # TODO better way to visualize convergence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac6aa4b5",
   "metadata": {},
   "source": [
    "# Train VDBE Epsilon Decay Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c12c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "vdbe_agent = train(vdbe_agent, num_episodes=num_turns_to_train, render=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fad342d",
   "metadata": {},
   "source": [
    "#### Visualize progress with one step: (q-update is ignored)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68dfad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train(vdbe_agent, 1, render=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10911c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "vdbe_agent.Q # TODO better way to visualize convergence"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
